{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "## Wednesday January 20 2016\n",
    "\n",
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Classification and Regression Trees\n",
    "\n",
    "'''\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Read, Explore, and Process data\n",
    "'''\n",
    "\n",
    "# Read in the data\n",
    "titanic = pd.read_csv('../../data/titanic.csv')\n",
    "\n",
    "# Take a  selection of the variables\n",
    "d = titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angus\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Angus\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Angus\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass  Spouse\n",
       "1       0         0.575342\n",
       "        1         0.742857\n",
       "2       0         0.473684\n",
       "        1         0.470588\n",
       "3       0         0.240786\n",
       "        1         0.250000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in all columns\n",
    "d.isnull().sum()\n",
    "d.groupby(['Sex', 'Pclass']).Age.apply(lambda x: x.isnull().sum()) / d.groupby(['Sex', 'Pclass']).Age.count()\n",
    "\n",
    "# Convert all variables to numeric so for scikit learn\n",
    "d['Sex'] = np.where(d.Sex == 'female', 1, 0)\n",
    "\n",
    "# Fill in missing values with the mean value (hint: use .fillna())\n",
    "d['Age'] = d['Age'].fillna(d['Age'].mean())\n",
    "\n",
    "# Explore the data to indtify trends in characteristics of survivors\n",
    "d.Survived.value_counts()                    # How many people lived and died\n",
    "d.Survived.mean()                            # The survival rate for everyone\n",
    "d.groupby('Sex').Survived.mean()             # By Sex: women have higher survival rates\n",
    "d.groupby('Pclass').Survived.mean()          # By Pclass: 1st class passengers have higher survival rates\n",
    "d.groupby(['Sex', 'Pclass']).Survived.mean() # By Sex and Pclass: Women in the 1st and 2nd classes had the highest survival rates\n",
    "\n",
    "# Create a proxy variable representing whether the Spouse was on board\n",
    "d['Spouse'] = ((d.Age > 18) & (d.SibSp >= 1)).astype(int)\n",
    "d.Spouse.value_counts()\n",
    "d.groupby(['Pclass', 'Spouse']).Survived.mean() # Having a spouse appears to increase survival in the 1st class only\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Spouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch  Spouse\n",
       "0         3    0  22.000000      1      0       1\n",
       "1         1    1  38.000000      1      0       1\n",
       "2         3    1  26.000000      0      0       0\n",
       "3         1    1  35.000000      1      0       1\n",
       "4         3    0  35.000000      0      0       0\n",
       "5         3    0  29.699118      0      0       0\n",
       "6         1    0  54.000000      0      0       0\n",
       "7         3    0   2.000000      3      1       0\n",
       "8         3    1  27.000000      0      2       0\n",
       "9         2    1  14.000000      1      0       0\n",
       "10        3    1   4.000000      1      1       0\n",
       "11        1    1  58.000000      0      0       0\n",
       "12        3    0  20.000000      0      0       0\n",
       "13        3    0  39.000000      1      5       1\n",
       "14        3    1  14.000000      0      0       0\n",
       "15        2    1  55.000000      0      0       0\n",
       "16        3    0   2.000000      4      1       0\n",
       "17        2    0  29.699118      0      0       0\n",
       "18        3    1  31.000000      1      0       1\n",
       "19        3    1  29.699118      0      0       0\n",
       "20        2    0  35.000000      0      0       0\n",
       "21        2    0  34.000000      0      0       0\n",
       "22        3    1  15.000000      0      0       0\n",
       "23        1    0  28.000000      0      0       0\n",
       "24        3    1   8.000000      3      1       0\n",
       "25        3    1  38.000000      1      5       1\n",
       "26        3    0  29.699118      0      0       0\n",
       "27        1    0  19.000000      3      2       1\n",
       "28        3    1  29.699118      0      0       0\n",
       "29        3    0  29.699118      0      0       0\n",
       "..      ...  ...        ...    ...    ...     ...\n",
       "861       2    0  21.000000      1      0       1\n",
       "862       1    1  48.000000      0      0       0\n",
       "863       3    1  29.699118      8      2       1\n",
       "864       2    0  24.000000      0      0       0\n",
       "865       2    1  42.000000      0      0       0\n",
       "866       2    1  27.000000      1      0       1\n",
       "867       1    0  31.000000      0      0       0\n",
       "868       3    0  29.699118      0      0       0\n",
       "869       3    0   4.000000      1      1       0\n",
       "870       3    0  26.000000      0      0       0\n",
       "871       1    1  47.000000      1      1       1\n",
       "872       1    0  33.000000      0      0       0\n",
       "873       3    0  47.000000      0      0       0\n",
       "874       2    1  28.000000      1      0       1\n",
       "875       3    1  15.000000      0      0       0\n",
       "876       3    0  20.000000      0      0       0\n",
       "877       3    0  19.000000      0      0       0\n",
       "878       3    0  29.699118      0      0       0\n",
       "879       1    1  56.000000      0      1       0\n",
       "880       2    1  25.000000      0      1       0\n",
       "881       3    0  33.000000      0      0       0\n",
       "882       3    1  22.000000      0      0       0\n",
       "883       2    0  28.000000      0      0       0\n",
       "884       3    0  25.000000      0      0       0\n",
       "885       3    1  39.000000      0      5       0\n",
       "886       2    0  27.000000      0      0       0\n",
       "887       1    1  19.000000      0      0       0\n",
       "888       3    1  29.699118      1      2       1\n",
       "889       1    0  26.000000      0      0       0\n",
       "890       3    0  32.000000      0      0       0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Split into training and test datasets, and build the model\n",
    "\n",
    "'''\n",
    "\n",
    "survived = d['Survived']\n",
    "del d['Survived']\n",
    "\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Spouse']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(d,survived, random_state=1)\n",
    "\n",
    "# Create a decision tree classifier instance (start out with a small tree for interpretability)\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "ctree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Create a feature vector\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# How to interpret the diagram?\n",
    "ctree.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict what will happen for 1st class woman\n",
    "features\n",
    "ctree.predict_proba([1, 1, 25, 0, 0, 0])\n",
    "ctree.predict([1, 1, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Predict what will happen for a 3rd class man\n",
    "ctree.predict_proba([3, 0, 25, 0, 0, 0])\n",
    "ctree.predict([3, 0, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angus\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77874177631578934"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Which features are the most important?\n",
    "ctree.feature_importances_\n",
    "\n",
    "# Clean up the output\n",
    "pd.DataFrame(zip(features, ctree.feature_importances_)).sort_index(by=1, ascending=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Confusion matrix\n",
    "pd.crosstab(y_test, preds, rownames=['actual'], colnames=['predicted'])\n",
    "\n",
    "# Make predictions on the test set using predict_proba\n",
    "probs = ctree.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate the AUC metric\n",
    "metrics.roc_auc_score(y_test, probs)\n",
    "\n",
    "# Decision Trees have notorouisly high variance, so what can we do\n",
    "# to better estimate the out of sample error of a high variance model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81393962679897347"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# compare AUC using cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(ctree, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# so far logistic regression is winning..\n",
    "\n",
    "'''\n",
    "\n",
    "FINE-TUNING THE TREE\n",
    "\n",
    "'''\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# check CV score for max depth = 3\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n",
    "\n",
    "# check CV score for max depth = 10\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=1, splitter='best'),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Conduct a grid search for the best tree depth\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1)\n",
    "depth_range = range(1, 20)\n",
    "param_grid = dict(max_depth=depth_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(d, survived)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f1da908>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngJK9iEgRULIXESkCSvYiIkXg/wOLuXOcjYTHMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4140978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Check out the scores of the grid search\n",
    "grid_mean_scores = [result[1] for result in grid.grid_scores_]\n",
    "\n",
    "\n",
    "# Plot the results of the grid search\n",
    "plt.figure()\n",
    "plt.plot(depth_range, grid_mean_scores)\n",
    "plt.hold(True)\n",
    "plt.grid(True)\n",
    "plt.plot(grid.best_params_['max_depth'], grid.best_score_, 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=1, splitter='best'),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the best estimator\n",
    "best = grid.best_estimator_\n",
    "\n",
    "cross_val_score(best, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# Still not as good as Logistic Regression.. \n",
    "# Let's try something else\n",
    "\n",
    "\n",
    "\n",
    "### EXERCISE ###\n",
    "#''' Use Grid Search try scan over three parameters\n",
    "#1. max_depth:     from 1 to 20\n",
    "#2. criterion:     (either 'gini' or 'entropy')\n",
    "#3. max_features : range (1,5)\n",
    "#\n",
    "#'''\n",
    "\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1,  criterion = \"entropy\")\n",
    "depth_range = range(1, 20)\n",
    "features_range = range(1, 5)\n",
    "param_grid = dict(max_depth=depth_range, max_features=features_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(d, survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854433056051\n",
      "0.853902342755\n"
     ]
    }
   ],
   "source": [
    "best = grid.best_estimator_\n",
    "\n",
    "print cross_val_score(best, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "print cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StringIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-50947bd2175f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m tree.export_graphviz(clf, out_file=dot_data,  \n\u001b[0;32m      8\u001b[0m                          \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StringIO' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pydot\n",
    "import os\n",
    "\n",
    "from IPython.display import Image  \n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  \n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angus\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:42: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beer_servings</td>\n",
       "      <td>0.421050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EU</td>\n",
       "      <td>0.342597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spirit_servings</td>\n",
       "      <td>0.180810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SA</td>\n",
       "      <td>0.030375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OC</td>\n",
       "      <td>0.019934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AF</td>\n",
       "      <td>0.004799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NA</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "0    beer_servings  0.421050\n",
       "4               EU  0.342597\n",
       "1  spirit_servings  0.180810\n",
       "6               SA  0.030375\n",
       "7               OC  0.019934\n",
       "5               AF  0.004799\n",
       "3               NA  0.000345\n",
       "2               AS  0.000089"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision trees (like many other classification models)\n",
    "# can also be used for regression!\n",
    "\n",
    "\n",
    "drinks = pd.read_csv('../../data/drinks.csv', na_filter=False)\n",
    "\n",
    "drinks\n",
    "\n",
    "# Make dummy columns for each of the 6 regions\n",
    "for continent_ in ['AS', 'NA', 'EU', 'AF', 'SA', 'OC']:\n",
    "    drinks[continent_] = drinks['continent'] == continent_\n",
    "\n",
    "drinks\n",
    "\n",
    "\n",
    "del drinks['continent']\n",
    "del drinks['country']\n",
    "del drinks['total_litres_of_pure_alcohol'] # this doesn't seem fair does it?\n",
    "\n",
    "X = drinks.drop('wine_servings', axis=1)\n",
    "y = drinks['wine_servings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "\n",
    "rtree = tree.DecisionTreeRegressor()\n",
    "\n",
    "rtree.fit(X_train, y_train)\n",
    "rtree.predict(X_test)\n",
    "\n",
    "printscores = cross_val_score(rtree, X, y, cv=10, scoring='mean_squared_error')\n",
    "mse_scores = -scores\n",
    "mse_scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores\n",
    "rmse_scores.mean()\n",
    "\n",
    "wine_mean = y.mean()\n",
    "wine_mean\n",
    "\n",
    "features = X.columns\n",
    "pd.DataFrame(zip(features, rtree.feature_importances_)).sort_index(by=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
